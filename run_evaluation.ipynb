{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'haptik'\n",
    "bot_name = 'curekart_subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inscope_accuracy(actual_node, pred_node):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for act, pred in zip(actual_node, pred_node):\n",
    "        if act == 'NO_NODES_DETECTED':\n",
    "            continue\n",
    "        total += 1\n",
    "        if act == pred:\n",
    "            correct += 1\n",
    "    return correct/total\n",
    "\n",
    "def get_oos_recall(actual_node, pred_node):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for act, pred in zip(actual_node, pred_node):\n",
    "        if act != 'NO_NODES_DETECTED':\n",
    "            continue\n",
    "        total += 1\n",
    "        if act == pred:\n",
    "            correct += 1\n",
    "    return correct/total\n",
    "\n",
    "def get_metrics(filepath, thresh):\n",
    "    df = pd.read_csv(filepath)\n",
    "    pred_node = []\n",
    "    for index, row in df.iterrows(): \n",
    "        if row['predicted_node_score'] < thresh:\n",
    "            pred_node.append('NO_NODES_DETECTED')\n",
    "        else:\n",
    "            pred_node.append(row['predicted_node'])\n",
    "    actual_node = list(df['label'])\n",
    "    accuracy = accuracy_score(actual_node, pred_node)\n",
    "    overall_f1 = f1_score(actual_node, pred_node, labels=list(set(actual_node)), average='weighted')\n",
    "    inscope_accuracy = get_inscope_accuracy(actual_node, pred_node)\n",
    "    oos_recall = get_oos_recall(actual_node, pred_node)\n",
    "    mcc = matthews_corrcoef(actual_node, pred_node)\n",
    "    return accuracy, overall_f1, inscope_accuracy, oos_recall, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Inscope Accuracy</th>\n",
       "      <th>OOS Recall</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.412714</td>\n",
       "      <td>0.348371</td>\n",
       "      <td>0.798673</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>0.396726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.546922</td>\n",
       "      <td>0.552749</td>\n",
       "      <td>0.780973</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.477374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.615540</td>\n",
       "      <td>0.633123</td>\n",
       "      <td>0.741150</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.505403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.708375</td>\n",
       "      <td>0.720889</td>\n",
       "      <td>0.701327</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.578202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.739657</td>\n",
       "      <td>0.743461</td>\n",
       "      <td>0.670354</td>\n",
       "      <td>0.797774</td>\n",
       "      <td>0.603908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.735621</td>\n",
       "      <td>0.731715</td>\n",
       "      <td>0.601770</td>\n",
       "      <td>0.847866</td>\n",
       "      <td>0.582559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.744702</td>\n",
       "      <td>0.728362</td>\n",
       "      <td>0.539823</td>\n",
       "      <td>0.916512</td>\n",
       "      <td>0.589812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.683148</td>\n",
       "      <td>0.626261</td>\n",
       "      <td>0.334071</td>\n",
       "      <td>0.975881</td>\n",
       "      <td>0.486639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.600404</td>\n",
       "      <td>0.485569</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>0.992579</td>\n",
       "      <td>0.309130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Accuracy  Weighted F1  Inscope Accuracy  OOS Recall       MCC\n",
       "0        0.1  0.412714     0.348371          0.798673    0.089054  0.396726\n",
       "1        0.2  0.546922     0.552749          0.780973    0.350649  0.477374\n",
       "2        0.3  0.615540     0.633123          0.741150    0.510204  0.505403\n",
       "3        0.4  0.708375     0.720889          0.701327    0.714286  0.578202\n",
       "4        0.5  0.739657     0.743461          0.670354    0.797774  0.603908\n",
       "5        0.6  0.735621     0.731715          0.601770    0.847866  0.582559\n",
       "6        0.7  0.744702     0.728362          0.539823    0.916512  0.589812\n",
       "7        0.8  0.683148     0.626261          0.334071    0.975881  0.486639\n",
       "8        0.9  0.600404     0.485569          0.132743    0.992579  0.309130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "accuracy_over_thresh = []\n",
    "overall_f1_over_thresh = []\n",
    "inscope_recall_over_thresh = []\n",
    "oos_recall_over_thresh = []\n",
    "mcc_over_thresh = []\n",
    "for thresh in thresholds:\n",
    "    accuracy, overall_f1, inscope_recall, oos_recall, mcc = get_metrics(f'preds/{platform}_{bot_name}.csv', thresh)\n",
    "    accuracy_over_thresh.append(accuracy)\n",
    "    overall_f1_over_thresh.append(overall_f1)\n",
    "    inscope_recall_over_thresh.append(inscope_recall)\n",
    "    oos_recall_over_thresh.append(oos_recall)\n",
    "    mcc_over_thresh.append(mcc)\n",
    "df_metrics = pd.DataFrame({'Threshold': thresholds,\n",
    "                           'Accuracy': accuracy_over_thresh,\n",
    "                           'Weighted F1': overall_f1_over_thresh,\n",
    "                          'Inscope Accuracy': inscope_recall_over_thresh,\n",
    "                          'OOS Recall': oos_recall_over_thresh,\n",
    "                          'MCC': mcc_over_thresh})\n",
    "df_metrics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.to_csv(f'results/{platform}_{bot_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMMUNITY',\n",
       " 'INTERNATIONAL_SHIPPING',\n",
       " 'MODES_OF_PAYMENTS',\n",
       " 'PORTAL_ISSUE',\n",
       " 'REFER_EARN',\n",
       " 'START_OVER',\n",
       " 'WORK_FROM_HOME'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.read_csv(f'preds/{platform}_{bot_name}.csv')\n",
    "set(df_res['predicted_node']) - set(df_res['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
